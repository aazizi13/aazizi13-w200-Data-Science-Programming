{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 12 Assignment - W200 Introduction to Data Science Programming, UC Berkeley MIDS\n",
    "\n",
    "Write code in this Jupyter Notebook to solve the following problems. This assignment addresses material covered in Unit 11. Please upload this **Notebook** with your solutions to your GitHub repository in your SUBMISSIONS/week_12 folder by 11:59PM PST the night before class. Do **NOT** push/upload the data file. If you turn-in anything on ISVC please do so under the Week 12 Assignment category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Explore and glean insights from a real dataset using pandas\n",
    "- Practice using pandas for exploratory analysis, information gathering, and discovery\n",
    "- Practice using matplotlib for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "You are to analyze campaign contributions to the 2016 U.S. presidential primary races made in California. Use the csv file located here: https://drive.google.com/file/d/1Lgg-PwXQ6TQLDowd6XyBxZw5g1NGWPjB/view?usp=sharing. You should download and save this file in the same folder as this notebook is stored.  This file originally came from the U.S. Federal Election Commission (https://www.fec.gov/).\n",
    "\n",
    "**DO NOT PUSH THIS FILE TO YOUR GITHUB REPO!**\n",
    "\n",
    "- Best practice is to not have DATA files in your code repo. As shown below, the default load is outside of the folder this notebook is in. If you change the folder where the file is stored please update the first cell!\n",
    "- If you do accidentally push the file to your github repo - follow the directions here to fix it: https://docs.google.com/document/d/15Irgb5V5G7pKPWgAerH7FPMpKeQRunbNflaW-hR2hTA/edit?usp=sharing\n",
    "\n",
    "Documentation for this data can be found here: https://drive.google.com/file/d/11o_SByceenv0NgNMstM-dxC1jL7I9fHL/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Guidelines:\n",
    "\n",
    "- This is a **real** dataset and so it may contain errors and other pecularities to work through\n",
    "- This dataset is ~218mb, which will take some time to load (and probably won't load in Google Sheets or Excel)\n",
    "- If you make assumptions, annotate them in your responses\n",
    "- While there is one code/markdown cell positioned after each question as a placeholder, some of your code/responses may require multiple cells\n",
    "- Double-click the markdown cells that say YOUR ANSWER HERE to enter your written answers. If you need more cells for your written answers, make them markdown cells (rather than code cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the two cells below. \n",
    "\n",
    "The first cell will load the data into a pandas dataframe named `contrib`. Note that a custom date parser is defined to speed up loading. If Python were to guess the date format, it would take even longer to load.  \n",
    "\n",
    "The second cell subsets the dataframe to focus on just the primary period through May 2016. Otherwise, we would see general election donations which would make it harder to draw conclusions about the primaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../P00000001-CA.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dd347e7b406c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Load the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# We have this defaulted to the folder OUTSIDE of your repo - please change it as needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mcontrib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../P00000001-CA.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'contb_receipt_dt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_parser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../P00000001-CA.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# These commands below set some options for pandas and to have matplotlib show the charts in the notebook\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "%matplotlib inline\n",
    "\n",
    "# Define a date parser to pass to read_csv\n",
    "d = lambda x: pd.datetime.strptime(x, '%d-%b-%y')\n",
    "\n",
    "# Load the data\n",
    "# We have this defaulted to the folder OUTSIDE of your repo - please change it as needed\n",
    "contrib = pd.read_csv('../../P00000001-CA.csv', index_col=False, parse_dates=['contb_receipt_dt'], date_parser=d)\n",
    "print(contrib.shape)\n",
    "\n",
    "# Note - for now, it is okay to ignore the warning about mixed types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data to primary period \n",
    "contrib = contrib.copy()[contrib['contb_receipt_dt'] <= datetime.datetime(2016, 5, 31)]\n",
    "print(contrib.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data  Exploration (20 points)\n",
    "\n",
    "**1a. First, take a preliminary look at the data.**\n",
    "- Print the *shape* of the data. What does this tell you about the number of variables and rows you have?\n",
    "- Print a list of column names. \n",
    "- Review the documentation for this data (link above). Do you have all of the columns you expect to have?\n",
    "- Sometimes variable names are not clear unless we read the documentation. In your own words, based on the documentation, what information does the `election_tp` variable contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9f7a7938e43b14d3c7c49d6a278b0bb1",
     "grade": true,
     "grade_id": "cell-5d017805206f18b1",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# contrib.shape: This tells us the number of rows followed by number of columns.\n",
    "\n",
    "contrib.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrib.columns: This print all the column names. \n",
    "# I have all the columns I expect.\n",
    "\n",
    "contrib.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e6a198453ec4b0171a064fef0bd7c678",
     "grade": true,
     "grade_id": "cell-3bc26919169bf4aa",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "election_type: shows us the election type; Primary election or General election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b. Print the first 5 rows from the dataset to manually check some of the data.** \n",
    "\n",
    "This is a good idea to ensure the data loaded and the columns parsed correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4fbf682f1c78b3614832c6f48ecd88c7",
     "grade": true,
     "grade_id": "cell-72bc97601b84f17d",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "contrib.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c. Pick three variables from the dataset above and run some quick sanity checks.**\n",
    "\n",
    "When working with a new dataset, it is important to explore and sanity check your variables. For example, you may want to examine the maximum and minimum values, a frequency count, or something else. Use the three markdown cells below to explain if your **three** chosen variables \"pass\" your sanity checks or if you have concerns about the integrity of your data and why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0ec29a2cabd52709322d1cfd650babe7",
     "grade": true,
     "grade_id": "cell-23b51536d24c1645",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "contrib['contbr_city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrib['contb_receipt_amt'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrib['cand_nm'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cfa64002e64474584dc1442b5a39b460",
     "grade": true,
     "grade_id": "cell-8a320c2ff7c24d98",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "1- contrib['contbr_city'].value_counts() passes my sanity check because it lists all the cities and occurences as expected.\\\n",
    "2- contrib['contb_receipt_amt'].max() passes my sanity check because it shows the maximum value for contb_receipt_amt column as expected.\\\n",
    "3- contrib['cand_nm'].unique() passes my sanity check because it shows all the unique candidates as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1d. Plotting a histogram** \n",
    "\n",
    "Make a histogram of **one** of the variables you picked above. What are some insights that you can see from this histogram? \n",
    "Remember to include on your histogram:\n",
    "- Include a title\n",
    "- Include axis labels\n",
    "- The correct number of bins to see the breakout of values\n",
    "- Hint: For some variables the range of values is very large. To do a better exploration, make the initial histogram the full range and then you can make a smaller histogram 'zoomed' in on a discreet range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize =(20,7))\n",
    "plt.xlabel('Candidate Names', color = 'red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Frequency of Contributions', color = 'red') \n",
    "plt.title(r'Frequency of Contributions Per Candidate', color = 'red') \n",
    "plt.hist(contrib['cand_nm'], bins = 23, ec ='black', align = 'left') \n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this histogram, we can see that Bernard Sanders had the highest frequency of contributions. Hillary clinton has the second place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring Campaign Contributions (30 points)\n",
    "\n",
    "Let's investigate the donations to the candidates.\n",
    "\n",
    "**2a. Present a table that shows the number of donations to each candidate sorted by number of donations.**\n",
    "\n",
    "- When presenting data as a table, it is often best to sort the data in a meaningful way. This makes it easier for your reader to examine what you've done and to glean insights.  From now on, all tables that you present in this assignment (and course) should be sorted.\n",
    "- Hint: Use the `groupby` method. Groupby is explained in Unit 13: async 13.3 & 13.5\n",
    "- Hint: Use the `sort_values` method to sort the data so that candidates with the largest number of donations appear on top.\n",
    "\n",
    "Which candidate received the largest number of contributions (variable 'contb_receipt_amt')?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "442b24601da06376c43cbe6ef5c5348a",
     "grade": true,
     "grade_id": "cell-6a453219105384dd",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "contribution_number = contrib.groupby(by='cand_nm')['contb_receipt_amt'].count().sort_values(ascending = False)\n",
    "contribution_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c5a1b7f30648cced7269ccb9b1532bd6",
     "grade": true,
     "grade_id": "cell-90c49bd6471a3dc9",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The candidate with largest number of contributions is Bernard Sanders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b. Now, present a table that shows the total value of donations to each candidate. sorted by total value of the donations**\n",
    "\n",
    "Which candidate raised the most money in California?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contributions_amount = contrib.groupby(by=\"cand_nm\")[\"contb_receipt_amt\"].sum().sort_values(ascending=False)\n",
    "contributions_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "60d3e303837e9603de5b96e32af7d806",
     "grade": true,
     "grade_id": "cell-447dc63eff8ebc5f",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Hillary Clinton had the highest amount of contributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c. Combine the tables (sorted by either a or b above).**\n",
    "\n",
    "- Looking at the two tables you presented above - if those tables are Series convert them to DataFrames.\n",
    "- Rename the variable (column) names to accurately describe what is presented.\n",
    "- Merge together your tables to show the *count* and the *value* of donations to each candidate in one table.\n",
    "- Hint: Use the `merge` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting the above two tables into data frames\n",
    "contribution_number_df = pd.DataFrame(contribution_number)\n",
    "contributions_amount_df = pd.DataFrame(contributions_amount)\n",
    "\n",
    "# Resetting indices for both tables.\n",
    "contribution_number_df.reset_index(inplace=True)\n",
    "contributions_amount_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# Remaning Column Names to properly reflect the data using dictionaries.\n",
    "contribution_number_df.rename(columns = {'contb_receipt_amt': 'total_number_of_contributions'}, inplace =True)\n",
    "contributions_amount_df.rename(columns = {'contb_receipt_amt': 'total_amount_of_contributions '},inplace = True)\n",
    "\n",
    "\n",
    "# Merging both tables together.  \n",
    "number_amount_contb = pd.merge(contribution_number_df, contributions_amount_df, on = 'cand_nm')\n",
    "number_amount_contb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d. Calculate and add a new variable to the table from 2c that shows the average \\$ per donation. Print this table sorted by the average donation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finding average $ per donation and creating a new column\n",
    "number_amount_contb['average_per_contribution'] = number_amount_contb['total_amount_of_contributions ']/ number_amount_contb['total_number_of_contributions']\n",
    "    \n",
    "#Sorting by average donation\n",
    "number_amount_contb.sort_values(by='average_per_contribution', ascending = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2e. Plotting a Bar Chart**\n",
    "\n",
    "Make a single bar chart that shows two different bars per candidate with one bar as the total value of the donations and the other as average $ per donation. \n",
    "- Show the Candidates Name on the x-axis\n",
    "- Show the amount on the y-axis\n",
    "- Include a title\n",
    "- Include axis labels\n",
    "- Hint: Make the y-axis a log-scale to show both numbers! (matplotlib docs: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.yscale.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_amount_contb.plot(x='cand_nm', y=['total_amount_of_contributions ', 'average_per_contribution'], \n",
    "                         kind=\"bar\", logy= True, figsize=(17,9),\n",
    "                         title= \"Total and Average Donations Per Candidate\",\n",
    "                         xlabel= 'Candidate Name', ylabel=\"Logarithmic Scale\") \n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2f. Comment on the results of your data analysis in a short paragraph.**\n",
    "\n",
    "- There are several interesting conclusions you can draw from the table you have created.\n",
    "- What have you learned about campaign contributions in California?\n",
    "- We are looking for data insights here rather than comments on the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- James Gilmore has the lowest number of contributions with a very high average. It is possible that these contributions are from family or friends or wealthy individuals.\\\n",
    "\n",
    "2- Bernard Sanders has the most number of contributions with very low average contributions. It is possible that these contributions are from general public, specificaly from poor or middle class.\\\n",
    "\n",
    "3- Hillary Clinton despite having fewer contributions than Bernard Sanders has the highest total amount of contributions. Her average is much higher than Bernard Sanders as well. It is possible that most of her supporters are from middle or upper class.\\\n",
    "\n",
    "4- Overall, both main democratic candidates have the most amount of contributions from California. It is possible that California is a very blue state. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring Donor Occupations (30 points)\n",
    "\n",
    "Above in part 2, we saw that some simple data analysis can give us insights into the campaigns of our candidates. Now let's quickly look to see what *kind* of person is donating to each campaign using the `contbr_occupation` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3a. Show the top 5 occupations of individuals that contributed to Hillary Clinton.** \n",
    "\n",
    "- Subset your data to create a dataframe with only donations for Hillary Clinton.\n",
    "- Then use the `value_counts` and `head` methods to present the top 5 occupations (`contbr_occupation`) for her donors.\n",
    "- Note: we are just interested in the count of donations, not the value of those donations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "20a71229316bf24a2ce62c52f72d8142",
     "grade": true,
     "grade_id": "cell-963603c5ed346a99",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "Hillary_Donations = contrib.loc[contrib['cand_nm'] == 'Clinton, Hillary Rodham']\n",
    "Donations_count = Hillary_Donations['contbr_occupation'].value_counts()\n",
    "Donations_count_df = pd.DataFrame(Donations_count)\n",
    "Donations_count_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "426b589a9d6457f38381eb1c77678d4f",
     "grade": true,
     "grade_id": "cell-b6fc3f7c906c95a2",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**3b. Write a function called `get_donors`.**\n",
    "\n",
    "Imagine that you want to do the previous operation on several candidates.  To keep your work neat, you want to take the work you did on the Clinton-subset and wrap it in a function that you can apply to other subsets of the data.\n",
    "\n",
    "- The function should take a DataFrame as a parameter, and return a Series containing the counts for the top 5 occupations contained in that DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "81ebf2a2f96961b4464f6c35d2143427",
     "grade": true,
     "grade_id": "cell-bea2cf7a6fff8565",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_donors(df):\n",
    "    \"\"\"This function takes a dataframe that contains a variable named contbr_occupation.\n",
    "    It outputs a Series containing the counts for the 5 most common values of that\n",
    "    variable.\"\"\"\n",
    "    \n",
    "    donations_count = df.value_counts()\n",
    "    donations_count_df = pd.DataFrame(donations_count)\n",
    "    return donations_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c. Now run the `get_donors` function on subsets of the dataframe corresponding to three candidates. Show each of the three candidates below.**\n",
    "\n",
    "- Hillary Clinton\n",
    "- Bernie Sanders\n",
    "- Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "bffd2778d22127102347386bfb6f5b20",
     "grade": true,
     "grade_id": "cell-4ad1da24176f0450",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Using loc function to locate each canditate in \"cand_nm\" column \n",
    "Hillary_donations = contrib.loc[contrib['cand_nm'] == 'Clinton, Hillary Rodham']\n",
    "Bernie_donations = contrib.loc[contrib['cand_nm'] == 'Sanders, Bernard']\n",
    "Trump_donations = contrib.loc[contrib['cand_nm'] == 'Trump, Donald J.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalling the function get_donors and finding the desired value for Hillary Clinton\n",
    "get_donors(Hillary_donations['contbr_occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalling the function get_donors and finding the desired value for Bernie Sanders\n",
    "get_donors(Bernie_donations['contbr_occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalling the function get_donors and finding the desired value for Donald Trump\n",
    "get_donors(Trump_donations['contbr_occupation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3d. Finally, use `groupby` to separate the entire dataset by candidate.**\n",
    "\n",
    "- Call .apply(get_donors) on your groupby object, which will apply the function you wrote to each subset of your data.\n",
    "- Look at your output and marvel at what pandas can do in just one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grouping cand_nm\n",
    "contritubtions_by_occupation = contrib.groupby('cand_nm')\n",
    "\n",
    "#using apply function to call our function. Using lambda function to look for all candidates.  \n",
    "contritubtions_by_occupation.apply(lambda x: get_donors(x['contbr_occupation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "14c2855e3d59f0da6b1afd5cf0da2da8",
     "grade": true,
     "grade_id": "cell-fd840cdd19d2bd2a",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**3e. Comment on your data insights & findings in a short paragraph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "43ce3d15cee7ab73f53fd8f054c9826c",
     "grade": true,
     "grade_id": "cell-dce8d3107c1463ca",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "1- It seems like retired people have been universally donating the most compared to all other subsets of occupations.\\\n",
    "2- Bernie Sanders received the most number of donations from unemployed people followed by retired people.\\\n",
    "3- Bernie Sanders also received a huge number of donations from teachers. \\\n",
    "4- James Gilmore received all his donations from wealthy individuals.\\\n",
    "5- Hillary Clinton received an overwhelming number of donations from retired people and attornies. \\\n",
    "6- There are many more insights that we can pull from there. I listed the interesting ones above. \\\n",
    "7- Not surprisingly, Trump did not have a lot of contributions from a blue state such as California. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3f. Think about your findings in section 3 vs. your findings in section 2 of this assignment.**\n",
    "\n",
    "Do you have any new data insights into the results you saw in section 2 now that you see the top occupations for each candidate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a5f4e6df0f32e24c492a9589ec87fef6",
     "grade": true,
     "grade_id": "cell-9e3f68b21dac8e10",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "1- James Gilmore did have wealthy donors.\\\n",
    "2- Bernie Sanders's majority of donors were from middle and low income people.\\\n",
    "3- Hillary Clinton had middle class and upper class donors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Plotting Data (20 points)\n",
    "\n",
    "There is an important element that we have not yet explored in this dataset - time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4a. Present a single line chart with the following elements.**\n",
    "\n",
    "- Show the date on the x-axis\n",
    "- Show the contribution amount on the y-axis\n",
    "- Include a title\n",
    "- Include axis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4f1a9e7ee0ded9d2b5af5777cb85e505",
     "grade": true,
     "grade_id": "cell-c14fbed9d72d54e3",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "contrib.plot(x = 'contb_receipt_dt', y = 'contb_receipt_amt', figsize=(20,9),\n",
    "                         title= \"Contributions Over Time \",\n",
    "                         xlabel= 'Date', ylabel=\"Contributions Amount\", ylim=([0,12000]), grid = True) \n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b. Make a better time-series line chart**\n",
    "\n",
    "This chart is messy and it is hard to gain insights from it.  Improve the chart from 4a so that your new chart shows a specific insight. In the spot provided, write the insight(s) that can be gained from this new time-series line chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6dc1481a003cdd752c5edfa9ac400879",
     "grade": true,
     "grade_id": "cell-f7a01ce9c5b10ac7",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "contribution_dates.plot(x = 'n', y = 'contb_receipt_amt', figsize=(23,14),\n",
    "                         title= \"Contributions Over Time \",\n",
    "                         xlabel= 'Date', ylabel=\"Contributions Amount\", ylim=([0,13000]), grid = True, color = 'red') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "010f5de5f6af4c7f830d1cf7a81bbc0f",
     "grade": true,
     "grade_id": "cell-5617179133b06d0c",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "1- As expected, donations increased as election for primaries approached.\\\n",
    "2- Based on the graph, we can see that the amount of donations started picking up after 04/2015. This may indicate the time candidates start annoucning that they will be running for president.  \n",
    "3- The amount of donations increased rapidly around 04/2016. This could possibly indicate the start of campaigning season of the candidates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you have feedback for this homework, please submit it using the link below:\n",
    "\n",
    "http://goo.gl/forms/74yCiQTf6k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
